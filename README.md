# ğŸ™ï¸ **Hindi Text-to-Speech (TTS) Fine-Tuned Model** ğŸ‡®ğŸ‡³  
This repository contains the fine-tuned **SpeechT5 TTS** model optimized for Hindi language text-to-speech synthesis. Leveraging the power of **Microsoft's SpeechT5**, this model delivers **natural, clear, and accurate speech generation** for Hindi text inputs.

---

## ğŸš€ **Project Overview**
The model addresses the growing demand for **Hindi speech synthesis** in applications such as **education, assistive technologies, voice assistants, and regional content generation**. It achieves high-quality outputs by fine-tuning the SpeechT5 model on a curated dataset of Hindi texts and corresponding audio.

---

## ğŸ› ï¸ **Features**
- **Accurate Pronunciation**: Fine-tuned to handle complex phonetics and Hindi-specific nuances.  
- **Natural Speech**: Produces clear and lifelike speech outputs.  
- **Flexible Usage**: Easily integrated into applications for real-time TTS.  
- **Customizable**: You can further fine-tune or optimize the model for specific tasks.  

---

## ğŸ“š **Applications** ğŸŒŸ  
1. **Voice Assistants** ğŸ¤–  
   - Creating Hindi-speaking AI assistants like Alexa, Google Assistant, etc.  

2. **Educational Tools** ğŸ“–  
   - Developing learning tools for regional students and visually impaired individuals.  

3. **Audiobooks & Podcasts** ğŸ§  
   - Generating Hindi audiobooks and content for entertainment or education.  

4. **Content Localization** ğŸŒ  
   - Localizing advertisements, videos, and digital platforms for Hindi-speaking audiences.  

5. **Accessibility Tools** â™¿  
   - Providing speech solutions for text accessibility.

---

## ğŸ”§ **Setup & Installation**
Follow these steps to use the model:

### **1. Clone the Repository**
```bash
git lfs install
git clone https://huggingface.co/Saurabh1207/Hindi_SpeechT5_finetuned
```

### **2. Install Dependencies**
Make sure you have Python and the necessary libraries installed.  
Run the following:
```bash
pip install git+https://github.com/huggingface/transformers.git accelerate datasets soundfile speechbrain torch
```

### **3. Inference Code: Generate Hindi Speech**
Hereâ€™s an example of how you can use the model to generate speech from Hindi text:

```python
import os
import torch
from IPython.display import Audio
import soundfile as sf
from speechbrain.pretrained import EncoderClassifier
from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan

# Load a sample from the dataset for speaker embedding
processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")
vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
spk_model_name = "speechbrain/spkrec-xvect-voxceleb"
device = "cuda" if torch.cuda.is_available() else "cpu"
speaker_model = EncoderClassifier.from_hparams(source=spk_model_name, run_opts={"device": device}, savedir=os.path.join("/tmp", spk_model_name))

try:
    dataset = load_dataset("mozilla-foundation/common_voice_17_0", "hi", split="validated", trust_remote_code=True)
    dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
    sample = dataset[0]
    speaker_embedding = create_speaker_embedding(sample['audio']['array'])

except Exception as e:
    print(f"Error loading dataset: {e}")
    # Use a random speaker embedding as fallback
    speaker_embedding = torch.randn(1, 512)

def create_speaker_embedding(waveform):
    with torch.no_grad():
        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))
        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2) 
        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()
    return speaker_embeddings

# Load processor and fine-tuned model
processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")
model = SpeechT5ForTextToSpeech.from_pretrained("Saurabh1207/Hindi_SpeechT5_finetuned")

# Define input text in Hindi
input_text = "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤¯à¤¹ à¤¹à¤¿à¤‚à¤¦à¥€ à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤Ÿà¥‚ à¤¸à¥à¤ªà¥€à¤š à¤®à¥‰à¤¡à¤² à¤•à¤¾ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ à¤¹à¥ˆà¥¤"

# Preprocess text
inputs = processor(text=input_text, return_tensors="pt")

# Generate speech
speech = model.generate_speech(inputs["input_ids"], speaker_embeddings, vocoder=vocoder)
Audio(speech.numpy(), rate=16000)

# Save audio file
sf.write("hindi_output.wav", speech.cpu().numpy(), 16000)
print("Hindi speech generated and saved as 'hindi_output.wav'")
```

---

## ğŸ§ Sample Outputs
Here are some audio samples generated by the Hindi TTS model:

1. **Sample 1**: [Play or Download](Fine_Tuned_Hindi_Audio/output_1.wav)  
2. **Sample 2**: [Play or Download](Fine_Tuned_Hindi_Audio/output_2.wav)  
3. **Sample 3**: [Play or Download](Fine_Tuned_Hindi_Audio/output_3.wav)  

---

## ğŸš€ **How to Fine-Tune Further?**
For advanced users, fine-tuning the model on a **custom dataset** is simple:  
1. Prepare a dataset with Hindi text and corresponding audio files.  
2. Use the Hugging Face `SpeechT5ForTextToSpeech` API to fine-tune the model further.  
3. Save and test the optimized model for improved results.

Refer to Hugging Face's documentation for details: [SpeechT5 Fine-Tuning Guide](https://huggingface.co/Saurabh1207/Hindi_SpeechT5_finetuned).  

---

## ğŸŒ **Documentation Links**  
Explore the official resources for models and libraries used in this project:  
- **SpeechT5 Overview**: [Microsoft SpeechT5 on Hugging Face](https://huggingface.co/microsoft/speecht5_tts)  
- **Transformers Library**: [Hugging Face Transformers](https://huggingface.co/docs/transformers/)  
- **PyTorch**: [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)  

---

## ğŸ“Š **Performance Metrics**
The fine-tuned Hindi TTS model achieves high performance in subjective and objective evaluations, focusing on:  
- **Pronunciation accuracy**  
- **Speech naturalness**  
- **Inference speed**  

Results demonstrate significant improvements over pre-trained models on Hindi datasets.  

---

## ğŸ’¡ **Future Improvements**
1. Expand the dataset for better coverage of accents and dialects.  
2. Integrate quantization for faster real-time inference.  
3. Optimize the model for deployment on low-resource devices.  

---

## ğŸ¤ **Contributing**
Contributions are welcome!  
If you find any issues or have suggestions, feel free to open an **issue** or **pull request**.  

---

## ğŸ§‘â€ğŸ’» **Contact & Support**
For queries or support, please reach out:  
- **Email**: [slsaurabh1234567890@gmail.com](mailto:slsaurabh1234567890@gmail.com)  
- **LinkedIn**: [Saurabh's LinkedIn Profile](https://www.linkedin.com/in/saurabh-kumar-o7o3/)  

---

## â­ **If you like this project, donâ€™t forget to give it a star!** â­  

<p align="center">
  <img src="https://img.shields.io/github/stars/yourusername/hindi-tts-finetuned?style=social" alt="GitHub Stars">
  <img src="https://img.shields.io/badge/License-MIT-blue" alt="License">
</p>

---

Let me know if you need any further tweaks, changes, or additional elements! ğŸš€


  
